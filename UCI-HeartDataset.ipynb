{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "columns = [\"age\", \"sex\", \"cp\", \"restbp\", \"chol\", \"fbs\", \"restecg\", \n",
    "           \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]\n",
    "df0     = pd.read_table(\"data/heart_disease_all14.csv\", sep=',', header=None, names=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of patients in dataframe: 299, with disease: 139, without disease: 160\n",
      "\n",
      "    age  sex  restbp   chol  fbs  thalach  exang  oldpeak   ca   hd  cp_1  \\\n",
      "0  63.0  1.0   145.0  233.0  1.0    150.0    0.0      2.3  0.0  0.0     1   \n",
      "1  67.0  1.0   160.0  286.0  0.0    108.0    1.0      1.5  3.0  1.0     0   \n",
      "2  67.0  1.0   120.0  229.0  0.0    129.0    1.0      2.6  2.0  1.0     0   \n",
      "3  37.0  1.0   130.0  250.0  0.0    187.0    0.0      3.5  0.0  0.0     0   \n",
      "4  41.0  0.0   130.0  204.0  0.0    172.0    0.0      1.4  0.0  0.0     0   \n",
      "\n",
      "   cp_2  cp_3  recg_1  recg_2  slope_1  slope_3  thal_6  thal_7  \n",
      "0     0     0       0       1        0        1       1       0  \n",
      "1     0     0       0       1        0        0       0       0  \n",
      "2     0     0       0       1        0        0       0       1  \n",
      "3     0     1       0       0        0        1       0       0  \n",
      "4     1     0       0       1        1        0       0       0  \n",
      "              age        sex      restbp        chol         fbs     thalach  \\\n",
      "count  299.000000  299.00000  299.000000  299.000000  299.000000  299.000000   \n",
      "mean    54.521739    0.67893  131.715719  246.785953    0.143813  149.327759   \n",
      "std      9.030264    0.46767   17.747751   52.532582    0.351488   23.121062   \n",
      "min     29.000000    0.00000   94.000000  100.000000    0.000000   71.000000   \n",
      "25%     48.000000    0.00000  120.000000  211.000000    0.000000  132.500000   \n",
      "50%     56.000000    1.00000  130.000000  242.000000    0.000000  152.000000   \n",
      "75%     61.000000    1.00000  140.000000  275.500000    0.000000  165.500000   \n",
      "max     77.000000    1.00000  200.000000  564.000000    1.000000  202.000000   \n",
      "\n",
      "            exang     oldpeak          ca          hd        cp_1        cp_2  \\\n",
      "count  299.000000  299.000000  299.000000  299.000000  299.000000  299.000000   \n",
      "mean     0.331104    1.058528    0.672241    0.464883    0.076923    0.163880   \n",
      "std      0.471399    1.162769    0.937438    0.499601    0.266916    0.370787   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.800000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      1.000000    1.600000    1.000000    1.000000    0.000000    0.000000   \n",
      "max      1.000000    6.200000    3.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "             cp_3      recg_1      recg_2     slope_1     slope_3      thal_6  \\\n",
      "count  299.000000  299.000000  299.000000  299.000000  299.000000  299.000000   \n",
      "mean     0.277592    0.013378    0.488294    0.464883    0.070234    0.060201   \n",
      "std      0.448562    0.115079    0.500701    0.499601    0.255970    0.238257   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      1.000000    0.000000    1.000000    1.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "           thal_7  \n",
      "count  299.000000  \n",
      "mean     0.391304  \n",
      "std      0.488860  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      1.000000  \n",
      "max      1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_clean_and_standardize_data_frame(df0):\n",
    "    # Convert categorical variables with more than two values into dummy variables.\n",
    "    # Note that variable ca is discrete but not categorical, so we don't convert it.\n",
    "    df      = df0.copy()\n",
    "    dummies = pd.get_dummies(df[\"cp\"],prefix=\"cp\")\n",
    "    df      = df.join(dummies)\n",
    "    del df[\"cp\"]\n",
    "    del df[\"cp_4.0\"]\n",
    "    df      = df.rename(columns = {\"cp_1.0\":\"cp_1\",\"cp_2.0\":\"cp_2\",\"cp_3.0\":\"cp_3\"})\n",
    "\n",
    "    dummies = pd.get_dummies(df[\"restecg\"],prefix=\"recg\")\n",
    "    df      = df.join(dummies)\n",
    "    del df[\"restecg\"]\n",
    "    del df[\"recg_0.0\"]\n",
    "    df      = df.rename(columns = {\"recg_1.0\":\"recg_1\",\"recg_2.0\":\"recg_2\"})\n",
    "\n",
    "    dummies = pd.get_dummies(df[\"slope\"],prefix=\"slope\")\n",
    "    df      = df.join(dummies)\n",
    "    del df[\"slope\"]\n",
    "    del df[\"slope_2.0\"]\n",
    "    df      = df.rename(columns = {\"slope_1.0\":\"slope_1\",\"slope_3.0\":\"slope_3\"})\n",
    "\n",
    "    dummies = pd.get_dummies(df[\"thal\"],prefix=\"thal\")\n",
    "    df      = df.join(dummies)\n",
    "    del df[\"thal\"]\n",
    "    del df[\"thal_3.0\"]\n",
    "    df      = df.rename(columns = {\"thal_6.0\":\"thal_6\",\"thal_7.0\":\"thal_7\"})\n",
    "\n",
    "    # Replace response variable values and rename\n",
    "    df[\"num\"].replace(to_replace=[1,2,3,4],value=1,inplace=True)\n",
    "    df      = df.rename(columns = {\"num\":\"hd\"})\n",
    "\n",
    "    # New list of column labels after the above operations\n",
    "    new_columns_1 = [\"age\", \"sex\", \"restbp\", \"chol\", \"fbs\", \"thalach\", \n",
    "                     \"exang\", \"oldpeak\", \"ca\", \"hd\", \"cp_1\", \"cp_2\",\n",
    "                     \"cp_3\", \"recg_1\", \"recg_2\", \"slope_1\", \"slope_3\",\n",
    "                     \"thal_6\", \"thal_7\"]\n",
    "\n",
    "    print('\\nNumber of patients in dataframe: %i, with disease: %i, without disease: %i\\n' \\\n",
    "          % (len(df.index),len(df[df.hd==1].index),len(df[df.hd==0].index)))\n",
    "    print(df.head())\n",
    "    print(df.describe())\n",
    "\n",
    "    # Standardize the dataframe\n",
    "    stdcols = [\"age\",\"restbp\",\"chol\",\"thalach\",\"oldpeak\"]\n",
    "    nrmcols = [\"ca\"]\n",
    "    stddf   = df.copy()\n",
    "    stddf[stdcols] = stddf[stdcols].apply(lambda x: (x-x.mean())/x.std())\n",
    "    stddf[nrmcols] = stddf[nrmcols].apply(lambda x: (x-x.mean())/(x.max()-x.min()))\n",
    "\n",
    "    new_columns_2 = new_columns_1[:9] + new_columns_1[10:]\n",
    "    new_columns_2.insert(0,new_columns_1[9])\n",
    "    stddf = stddf.reindex(columns=new_columns_2)\n",
    "    \n",
    "    return stddf, new_columns_2\n",
    "\n",
    "\n",
    "    return (Xall, yall, new_columns_2)\n",
    "stddf, columns = get_clean_and_standardize_data_frame(df0)\n",
    "\n",
    "\n",
    "# Convert dataframe into lists for use by classifiers\n",
    "yall = stddf[\"hd\"]\n",
    "Xall = stddf[columns[1:]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "LogisticRegression score on full data set: 0.876254\n",
      "\n",
      "\n",
      "Classification report on full data set:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.93      0.89       160\n",
      "        1.0       0.90      0.82      0.86       139\n",
      "\n",
      "avg / total       0.88      0.88      0.88       299\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[148  12]\n",
      " [ 25 114]]\n",
      "\n",
      "LogisticRegression coefficients:\n",
      "      age : -0.03697\n",
      "      sex :  1.07496\n",
      "   restbp :  0.31269\n",
      "     chol :  0.16268\n",
      "      fbs : -0.34533\n",
      "  thalach : -0.43907\n",
      "    exang :  0.65986\n",
      "  oldpeak :  0.44011\n",
      "       ca :  2.42265\n",
      "     cp_1 : -1.33059\n",
      "     cp_2 : -0.65864\n",
      "     cp_3 : -1.37985\n",
      "   recg_1 :  0.11286\n",
      "   recg_2 :  0.37125\n",
      "  slope_1 : -0.76523\n",
      "  slope_3 : -0.42006\n",
      "   thal_6 :  0.07583\n",
      "   thal_7 :  1.25100\n",
      "Intercept : -0.667321\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def fit_logistic_model(Xall, yall):\n",
    "    model = LogisticRegression(fit_intercept=True)\n",
    "    print(model)\n",
    "    lrfit = model.fit(Xall,yall)\n",
    "    print('\\nLogisticRegression score on full data set: %f\\n' % lrfit.score(Xall,yall))\n",
    "    ypred = model.predict(Xall)\n",
    "    print('\\nClassification report on full data set:')\n",
    "    print(metrics.classification_report(yall,ypred))\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(metrics.confusion_matrix(yall,ypred))\n",
    "    print('\\nLogisticRegression coefficients:')\n",
    "    coeff = model.coef_.tolist()[0]\n",
    "    for index in range(len(coeff)):\n",
    "        print('%s : %8.5f' % (columns[index+1].rjust(9),coeff[index]))\n",
    "    print('Intercept : %f' %model.intercept_)\n",
    "    \n",
    "fit_logistic_model(Xall, yall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pujun/Desktop/ML/venv/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stddf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6e600458fb4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdropped_columns\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Drop all features except 1 (age) and 6 (thalach).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf1\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mstddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf1\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf1\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropped_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stddf' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Fit using only the age and thalach features, separately for ca=0 and ca>0.\n",
    "'''\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "dropped_columns  = [2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18] # Drop all features except 1 (age) and 6 (thalach).\n",
    "\n",
    "df1        = stddf.copy()\n",
    "df1        = df1[df1.ca<0]\n",
    "df1        = df1.drop(df1.columns[dropped_columns],axis=1) \n",
    "X_all_2_cols = df1[df1.columns[1:]]\n",
    "yall_2_cols   = df1[df1.columns[0]]\n",
    "\n",
    "fit_logistic_model(X_all_2_cols, yall_2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
